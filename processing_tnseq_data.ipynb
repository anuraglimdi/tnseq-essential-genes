{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d734d69",
   "metadata": {},
   "source": [
    "## Processing TnSeq mutant trajectory data for classification\n",
    "\n",
    "The transposon sequencing data contains counts for insertion mutants over the course of the fitness assay. Here, I will process this data into a set of features that can be used as an input for the machine learning classification algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49209a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from Bio.SeqIO.FastaIO import SimpleFastaParser\n",
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49182b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#current working directory\n",
    "repo = os.getcwd()\n",
    "print(repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b68355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style('ticks')\n",
    "sns.set_theme()\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd2ab12",
   "metadata": {},
   "source": [
    "### Loading all the metadata for this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060befb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_path = repo +'/Metadata/'\n",
    "data_path = repo + '/Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29933f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the pandas file with all the metadata!\n",
    "all_data = pd.read_csv(metadata_path+\"all_metadata_REL606.txt\", sep=\"\\t\")\n",
    "names = all_data.iloc[:,0]\n",
    "gene_start = all_data.iloc[:,3]\n",
    "gene_end = all_data.iloc[:,4]\n",
    "strand = all_data.iloc[:,5]\n",
    "locations = np.transpose(np.vstack([gene_start,gene_end,strand]))\n",
    "k12_tags = all_data.iloc[:,2]\n",
    "uniprot_rel606 = all_data.iloc[:,6]\n",
    "product = all_data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fractions of the gene at the 5' and 3' ends to be excluded from analysis because they insertions there may not actually\n",
    "#be disruptive to protein function\n",
    "frac5p = 0.1\n",
    "frac3p = 0.25\n",
    "\n",
    "with open(metadata_path+\"rel606_reference.fasta\") as in_handle:\n",
    "    for title, seq in SimpleFastaParser(in_handle):\n",
    "        ta_sites = [m.start(0) for m in re.finditer('TA', seq)]\n",
    "ta_sites = np.array(ta_sites)\n",
    "\n",
    "#counting how many TA sites are present in each gene\n",
    "ta_gene = np.zeros(len(names))\n",
    "for i in range(0,len(names)):\n",
    "    start = locations[i, 0]\n",
    "    end = locations[i, 1]\n",
    "    length = end - start\n",
    "    #if the gene is on the forward strand\n",
    "    if locations[i,2]==1:\n",
    "        #counting sites only in the middle 80% of the gene, excluding 10% at each end\n",
    "        ta_gene[i] = np.sum((ta_sites > start+length*frac5p)&(ta_sites < end - length*frac3p))\n",
    "    elif locations[i,2]==-1:\n",
    "        ta_gene[i] = np.sum((ta_sites < start+length*frac5p)&(ta_sites > end - length*frac3p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707aebce",
   "metadata": {},
   "source": [
    "### Compiling all the data for the sequencing experiment\n",
    "\n",
    "Organization of counts_data:\n",
    "- column 0: TA site coordinate\n",
    "- column 1: reads at t0, no UMI correction\n",
    "- column 2: reads at t0, UMI correction\n",
    "\n",
    "We are interested in column 2: the data at t0 will allow us to classify genes as essential or not in LB (as the selection occurred in LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts_data = np.loadtxt(data_path+'/green_methods_new_merged_all_TAsites.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(data, n_downsampled, random_seed):\n",
    "    \"\"\"\n",
    "    Inputs: \n",
    "    - data: counts matrix for bulk fitness assay\n",
    "    - scale: scaling factor for downsampling, must be greater than 1.\n",
    "    \n",
    "    Process:\n",
    "    - downsample number of reads mapping to an insertion site as follows (for each time point, here: by row)\n",
    "    - use np.repeat to get an list with every insertion site repeated N times, where N is the number of mapped reads\n",
    "    - use np.shuffle to rearrange this list\n",
    "    - pick the first 1/scale fraction of this list\n",
    "    - use np.unique to which sites are represented, and how frequently after downsampling.\n",
    "    \n",
    "    Output:\n",
    "    - data_scaled: same shape as data but each row of the matrix downsampled by the scaling factor\n",
    "    \"\"\"\n",
    "    \n",
    "    assert data.sum() >= n_downsampled, f\"n_downsampled must be less than sum(data)\"\n",
    "    \n",
    "    if data.sum() == n_downsampled: #do not downsample the data at all:\n",
    "        return data\n",
    "    \n",
    "    else:\n",
    "        np.random.seed(random_seed)\n",
    "        data_scaled = np.zeros_like(data)\n",
    "        #this is the key step in the process, every TA site is repeated as many times as number of reads mapping to it\n",
    "        explicit_data = np.repeat(np.arange(0,data.shape[0]), data.astype('int'))\n",
    "        #this list is then shuffled\n",
    "        np.random.shuffle(explicit_data)\n",
    "        #as we shuffled the data, taking the first N_ds reads is equivalent to taking a 1/scale random subset of the data\n",
    "        downsampled = explicit_data[:n_downsampled]\n",
    "        #getting the counts and unique TA sites represented after downsampling\n",
    "        unique, counts = np.unique(downsampled, return_counts=True)\n",
    "        data_scaled[unique] = counts\n",
    "        \n",
    "        return data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf48c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = 10**7  # we are normalizing our data to this value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cff715e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ds = downsample(counts_data[2],n_downsampled=norm, random_seed=42) #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a749c8e6",
   "metadata": {},
   "source": [
    "### Some more useful functions for extracting specific regions of a gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa425b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_gene_interior(locations,ta_sites,i):\n",
    "    start = locations[i, 0]\n",
    "    end = locations[i, 1]\n",
    "    length = end - start\n",
    "    #if the gene is on the forward strand\n",
    "    if locations[i,2]==1:\n",
    "        search_area = (ta_sites > start+length*frac5p)&(ta_sites < end - length*frac3p)\n",
    "    #if the gene is on the reverse strand\n",
    "    elif locations[i,2]==-1:\n",
    "        search_area = (ta_sites < start+length*frac5p)&(ta_sites > end - length*frac3p)\n",
    "    return search_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ff8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_gene_5p(locations,ta_sites,i):\n",
    "    start = locations[i, 0]\n",
    "    end = locations[i, 1]\n",
    "    length = end - start\n",
    "    #if the gene is on the forward strand\n",
    "    if locations[i,2]==1:\n",
    "        search_area = (ta_sites < start+length*frac5p)&(ta_sites > start)\n",
    "    #if the gene is on the reverse strand\n",
    "    elif locations[i,2]==-1:\n",
    "        search_area = (ta_sites > start+length*frac5p)&(ta_sites < start)\n",
    "\n",
    "    return search_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf60e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_gene_3p(locations,ta_sites,i):\n",
    "    start = locations[i, 0]\n",
    "    end = locations[i, 1]\n",
    "    length = end - start\n",
    "    #if the gene is on the forward strand\n",
    "    if locations[i,2]==1:\n",
    "        search_area = (ta_sites > end-length*frac3p)&(ta_sites < end)\n",
    "    #if the gene is on the reverse strand\n",
    "    elif locations[i,2]==-1:\n",
    "        search_area = (ta_sites < end-length*frac3p)&(ta_sites > end)\n",
    "    return search_area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafd4704",
   "metadata": {},
   "source": [
    "## Brainstorming set of features to extract for each gene\n",
    "\n",
    "- ta_sites: number of TA insertion sites within the gene interior\n",
    "- length: length of gene\n",
    "- reads5p: number of reads mapping to TA sites at the 5' end of the gene\n",
    "- reads3p: number of reads mapping to TA sites at the 3' end of the gene\n",
    "- normalized_coverage: number of reads mapping to the interior of the gene\n",
    "\n",
    "All the metrics calculated henceforth are using an the normalized coverage\n",
    "\n",
    "- insertion_index: normalized_coverage/length of gene interior (gene length*0.65)\n",
    "- f_zeros: fraction of TA sites with zero reads mapped\n",
    "- f_min_thresh: fraction of TA sites with at least min_thresh reads\n",
    "- zero_interval: extent of longest string of 0 coverage sites \n",
    "- median: median number of reads mapping to the gene interior\n",
    "- upper25: interquartile range Q3\n",
    "- lower25: interquartile range Q1\n",
    "\n",
    "As a first pass, I will normalize coverage to ~10 million reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d451e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2518704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_rows(gene, thresh):\n",
    "    \"\"\"\n",
    "    Input: gene number\n",
    "    Output: a dictionary containing values for all the features for gene\n",
    "    \"\"\"\n",
    "    \n",
    "    if ta_gene[gene] < 1: # if there are no sites in the interior of the gene (which can happen sometimes)\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        row_dict = {}\n",
    "        row_dict['Gene'] = gene\n",
    "        row_dict['Gene_name'] = names[gene]\n",
    "        row_dict['TA_sites_interior'] = ta_gene[gene]\n",
    "        row_dict['Gene_length'] = np.abs(locations[gene,1]-locations[gene,0])\n",
    "        if np.sum(search_gene_5p(locations,ta_sites,gene))==0:\n",
    "            row_dict['Mean_counts_5p_10pct'] = 0\n",
    "        else:\n",
    "            row_dict['Mean_counts_5p_10pct'] = np.mean(data_ds[search_gene_5p(locations,ta_sites,gene)])\n",
    "        \n",
    "        if np.sum(search_gene_3p(locations,ta_sites,gene))==0:\n",
    "            row_dict['Mean_counts_3p_25pct'] = 0\n",
    "        else:\n",
    "            row_dict['Mean_counts_3p_25pct'] = np.mean(data_ds[search_gene_3p(locations,ta_sites,gene)])\n",
    "        gene_interior = data_ds[search_gene_interior(locations,ta_sites,gene)]\n",
    "        row_dict['Mean_counts_interior'] = np.mean(gene_interior)\n",
    "        row_dict['Insertion_index'] = np.mean(gene_interior)/np.abs(locations[gene,1]-locations[gene,0])/0.65\n",
    "        row_dict['Fraction_zeros'] = np.sum(gene_interior==0)/ta_gene[gene]\n",
    "        row_dict['Fraction_above_thresh'] = np.sum(gene_interior>thresh)/ta_gene[gene]\n",
    "        row_dict['Median_counts'] = np.median(gene_interior)\n",
    "        row_dict['Upper25'] = np.percentile(gene_interior,75)\n",
    "        row_dict['Lower25'] = np.percentile(gene_interior,25)\n",
    "        if np.min(gene_interior)==0:\n",
    "            max_zeros = max(len(list(y)) for (c,y) in itertools.groupby(gene_interior) if c==0)\n",
    "        else:\n",
    "            max_zeros = 0\n",
    "        row_dict['Zeros_interval'] = max_zeros/ta_gene[gene]\n",
    "        \n",
    "        return row_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9625bf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 5 #parameter that can be tuned (ideally should scale with norm)\n",
    "#rule of thumb: thresh = norm/(2*10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd51e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = [construct_rows(gene,thresh=thresh) for gene in range(len(names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea55c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_list = list(filter(None, rows_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f46960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = pd.DataFrame(rows_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d611f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.set_index('Gene', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d989473",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.to_csv('tnseq_features_REL606.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
